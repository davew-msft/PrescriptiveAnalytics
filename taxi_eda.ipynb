{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis using Synapse Serverless over a Lakehouse\n",
    "\n",
    "Let's look at some basic EDA patterns using the NYC taxi dataset.  \n",
    "\n",
    "We can enrich the data using external datasets. \n",
    "\n",
    "## Business Problem: \n",
    "\n",
    "There are a few anomalies where ridership drops.  Could we determine if the cause might be weather?\n",
    "\n",
    "\n",
    "\n",
    "_This is my standard EDA SQL template_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./scripts/imports.py\n",
    "%run ./scripts/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars cell\n",
    "# sqlalchemy-formatted strings for Jupyter %sql magics to work\n",
    "sqlserver=\"asaworkspacedavew891-ondemand.sql.azuresynapse.net\"\n",
    "dbname=\"taxiAnalytics\"\n",
    "dbuname=\"asa.sql.admin\"\n",
    "dbpwd=\"\"\n",
    "connstring = 'Driver={{ODBC Driver 18 for SQL Server}};Server=tcp:{},1433;Database={};Uid={};Pwd={};Encrypt=yes;TrustServerCertificate=yes;Connection Timeout=30;'.format(sqlserver,dbname,dbuname,dbpwd)\n",
    "connstring = urllib.parse.quote_plus(connstring)\n",
    "connstring = 'mssql+pyodbc:///?odbc_connect={}'.format(connstring)\n",
    "#print(connstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql $connstring\n",
    "%config SqlMagic.displaycon = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Synapse Serverless Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "--best to start with a new SQL SERVERLESS db\n",
    "CREATE DATABASE taxiAnalytics\n",
    "GO\n",
    "USE taxiAnalytics\n",
    "GO\n",
    "\n",
    "--we need to set our db to utf-8 so parquet works properly\n",
    "ALTER DATABASE taxiAnalytics \n",
    "    COLLATE Latin1_General_100_BIN2_UTF8;\n",
    "\n",
    "--we need to setup some security and credentials\n",
    "IF NOT EXISTS (SELECT * FROM sys.symmetric_keys) \n",
    "BEGIN\n",
    "    CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'Password01!!' ;\n",
    "END;\n",
    "\n",
    "--file format definitions\n",
    "IF (EXISTS(SELECT * FROM sys.external_file_formats WHERE name = 'ParquetFF')) BEGIN\n",
    "    DROP EXTERNAL FILE FORMAT ParquetFF\n",
    "END\n",
    "CREATE EXTERNAL FILE FORMAT [ParquetFF] WITH (\n",
    "    FORMAT_TYPE = PARQUET,\n",
    "    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'\n",
    ");\n",
    "IF (EXISTS(SELECT * FROM sys.external_file_formats WHERE name = 'DeltaFF')) BEGIN\n",
    "    DROP EXTERNAL FILE FORMAT DeltaFF\n",
    "END\n",
    "CREATE EXTERNAL FILE FORMAT [DeltaFF] WITH (\n",
    "    FORMAT_TYPE = DELTA\n",
    ");\n",
    "GO\n",
    "--build a connection to our sandbox data lake (where we \"write\" data during development)\n",
    "--I think the best practice is to use the Primary data lake associated with the workspace\n",
    "IF EXISTS (SELECT * FROM sys.database_scoped_credentials WHERE name = 'WorkspaceIdentity')\n",
    "   DROP DATABASE SCOPED CREDENTIAL [WorkspaceIdentity]\n",
    "GO\n",
    "CREATE DATABASE SCOPED CREDENTIAL WorkspaceIdentity WITH IDENTITY = 'Managed Identity'\n",
    "GO\n",
    "IF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'sandbox')) BEGIN\n",
    "    DROP EXTERNAL DATA SOURCE sandbox;\n",
    "END\n",
    "GO\n",
    "CREATE EXTERNAL DATA SOURCE sandbox\n",
    "WITH (    LOCATION   = 'https://asadatalakedavew891.dfs.core.windows.net/sandbox',\n",
    "          CREDENTIAL = WorkspaceIdentity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Info for External Data Lakes\n",
    "\n",
    "    I use SAS tokens to look at 3rd party data lakes.  \n",
    "    We can also visually explore the data in a local data lake --OR-- using AzStorageExplorer\n",
    "\n",
    "    https://davewdemodata.dfs.core.windows.net/lake/gold/nyctlc/\n",
    "\n",
    "    Let's assume you want to query MY datalake as a third party data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>vendorID</th>\n",
       "        <th>tpepPickupDateTime</th>\n",
       "        <th>tpepDropoffDateTime</th>\n",
       "        <th>passengerCount</th>\n",
       "        <th>tripDistance</th>\n",
       "        <th>puLocationId</th>\n",
       "        <th>doLocationId</th>\n",
       "        <th>startLon</th>\n",
       "        <th>startLat</th>\n",
       "        <th>endLon</th>\n",
       "        <th>endLat</th>\n",
       "        <th>rateCodeId</th>\n",
       "        <th>storeAndFwdFlag</th>\n",
       "        <th>paymentType</th>\n",
       "        <th>fareAmount</th>\n",
       "        <th>extra</th>\n",
       "        <th>mtaTax</th>\n",
       "        <th>improvementSurcharge</th>\n",
       "        <th>tipAmount</th>\n",
       "        <th>tollsAmount</th>\n",
       "        <th>totalAmount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 14:18:03</td>\n",
       "        <td>2008-12-31 14:57:03</td>\n",
       "        <td>1</td>\n",
       "        <td>16.48</td>\n",
       "        <td>132</td>\n",
       "        <td>137</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>2</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>52.0</td>\n",
       "        <td>4.5</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>5.76</td>\n",
       "        <td>63.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:07:58</td>\n",
       "        <td>2008-12-31 23:15:35</td>\n",
       "        <td>5</td>\n",
       "        <td>1.02</td>\n",
       "        <td>140</td>\n",
       "        <td>236</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>7.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 21:35:46</td>\n",
       "        <td>2008-12-31 21:46:46</td>\n",
       "        <td>1</td>\n",
       "        <td>1.85</td>\n",
       "        <td>90</td>\n",
       "        <td>114</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>1</td>\n",
       "        <td>9.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>2.06</td>\n",
       "        <td>0.0</td>\n",
       "        <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:04:46</td>\n",
       "        <td>2008-12-31 23:06:59</td>\n",
       "        <td>1</td>\n",
       "        <td>0.0</td>\n",
       "        <td>158</td>\n",
       "        <td>158</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>2.5</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:29:13</td>\n",
       "        <td>2008-12-31 23:42:29</td>\n",
       "        <td>1</td>\n",
       "        <td>1.51</td>\n",
       "        <td>164</td>\n",
       "        <td>230</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>9.5</td>\n",
       "        <td>1.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:02:45</td>\n",
       "        <td>2008-12-31 23:12:13</td>\n",
       "        <td>1</td>\n",
       "        <td>0.88</td>\n",
       "        <td>68</td>\n",
       "        <td>48</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>7.5</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:26:39</td>\n",
       "        <td>2008-12-31 23:33:03</td>\n",
       "        <td>1</td>\n",
       "        <td>0.93</td>\n",
       "        <td>230</td>\n",
       "        <td>163</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>6.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:29:20</td>\n",
       "        <td>2008-12-31 23:34:54</td>\n",
       "        <td>1</td>\n",
       "        <td>0.57</td>\n",
       "        <td>140</td>\n",
       "        <td>237</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>5.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 23:18:00</td>\n",
       "        <td>2008-12-31 23:25:15</td>\n",
       "        <td>2</td>\n",
       "        <td>1.01</td>\n",
       "        <td>239</td>\n",
       "        <td>238</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>1</td>\n",
       "        <td>N</td>\n",
       "        <td>2</td>\n",
       "        <td>5.5</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.0</td>\n",
       "        <td>0.0</td>\n",
       "        <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>2008-12-31 16:07:11</td>\n",
       "        <td>2008-12-31 17:38:11</td>\n",
       "        <td>5</td>\n",
       "        <td>21.61</td>\n",
       "        <td>143</td>\n",
       "        <td>132</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>2</td>\n",
       "        <td>N</td>\n",
       "        <td>1</td>\n",
       "        <td>52.0</td>\n",
       "        <td>4.5</td>\n",
       "        <td>0.5</td>\n",
       "        <td>0.3</td>\n",
       "        <td>15.76</td>\n",
       "        <td>5.76</td>\n",
       "        <td>78.82</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('2', datetime.datetime(2008, 12, 31, 14, 18, 3), datetime.datetime(2008, 12, 31, 14, 57, 3), 1, 16.48, '132', '137', None, None, None, None, 2, 'N', '2', 52.0, 4.5, 0.5, '0.3', 0.0, 5.76, 63.06),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 7, 58), datetime.datetime(2008, 12, 31, 23, 15, 35), 5, 1.02, '140', '236', None, None, None, None, 1, 'N', '2', 7.0, 0.0, 0.5, '0.3', 0.0, 0.0, 7.8),\n",
       " ('2', datetime.datetime(2008, 12, 31, 21, 35, 46), datetime.datetime(2008, 12, 31, 21, 46, 46), 1, 1.85, '90', '114', None, None, None, None, 1, 'N', '1', 9.0, 0.5, 0.5, '0.3', 2.06, 0.0, 12.36),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 4, 46), datetime.datetime(2008, 12, 31, 23, 6, 59), 1, 0.0, '158', '158', None, None, None, None, 1, 'N', '2', 2.5, 0.0, 0.5, '0.3', 0.0, 0.0, 3.3),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 29, 13), datetime.datetime(2008, 12, 31, 23, 42, 29), 1, 1.51, '164', '230', None, None, None, None, 1, 'N', '2', 9.5, 1.0, 0.5, '0.3', 0.0, 0.0, 11.3),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 2, 45), datetime.datetime(2008, 12, 31, 23, 12, 13), 1, 0.88, '68', '48', None, None, None, None, 1, 'N', '2', 7.5, 0.0, 0.5, '0.3', 0.0, 0.0, 8.3),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 26, 39), datetime.datetime(2008, 12, 31, 23, 33, 3), 1, 0.93, '230', '163', None, None, None, None, 1, 'N', '2', 6.0, 0.0, 0.5, '0.3', 0.0, 0.0, 6.8),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 29, 20), datetime.datetime(2008, 12, 31, 23, 34, 54), 1, 0.57, '140', '237', None, None, None, None, 1, 'N', '2', 5.0, 0.0, 0.5, '0.3', 0.0, 0.0, 5.8),\n",
       " ('2', datetime.datetime(2008, 12, 31, 23, 18), datetime.datetime(2008, 12, 31, 23, 25, 15), 2, 1.01, '239', '238', None, None, None, None, 1, 'N', '2', 5.5, 0.0, 0.5, '0.3', 0.0, 0.0, 8.8),\n",
       " ('2', datetime.datetime(2008, 12, 31, 16, 7, 11), datetime.datetime(2008, 12, 31, 17, 38, 11), 5, 21.61, '143', '132', None, None, None, None, 2, 'N', '1', 52.0, 4.5, 0.5, '0.3', 15.76, 5.76, 78.82)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "--connect to the \"remote\" data lake\n",
    "--this is a container-based \"rle\" SAS token\n",
    "IF (EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'davewdemolake')) BEGIN\n",
    "    DROP EXTERNAL DATA SOURCE davewdemolake\n",
    "END\n",
    "\n",
    "IF EXISTS\n",
    "   (SELECT * FROM sys.database_scoped_credentials WHERE name = 'davewdemolakeCred')\n",
    "   DROP DATABASE SCOPED CREDENTIAL [davewdemolakeCred]\n",
    "\n",
    "CREATE DATABASE SCOPED CREDENTIAL davewdemolakeCred\n",
    "WITH IDENTITY = 'SHARED ACCESS SIGNATURE',\n",
    "--container level SAS with rle\n",
    "SECRET = 'sp=rle&st=2021-02-15T20:57:11Z&se=2032-02-16T04:57:11Z&spr=https&sv=2020-08-04&sr=c&sig=1v3rK0g6uK3sGHNesqIQqWxPbr3s7Pe%2FD4tNYBmD2oQ%3D'\n",
    "\n",
    "CREATE EXTERNAL DATA SOURCE davewdemolake\n",
    "WITH (    LOCATION   = 'https://davewdemodata.dfs.core.windows.net/lake',\n",
    "          CREDENTIAL = davewdemolakeCred\n",
    ")\n",
    "\n",
    "--let's make sure we can connect\n",
    "SELECT TOP 10 * FROM\n",
    "    OPENROWSET(\n",
    "        BULK 'gold/nyctlc-yellow/puYear=*/puMonth=*/*.parquet',\n",
    "        FORMAT='PARQUET',\n",
    "        DATA_SOURCE='davewdemolake'\n",
    "    ) AS result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "\n",
    "All of the above is template setup.  \n",
    "\n",
    "Let's look at one decade of taxi data, summarized by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>current_year</th>\n",
       "        <th>rides_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2010</td>\n",
       "        <td>169001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2011</td>\n",
       "        <td>176897208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2012</td>\n",
       "        <td>178544324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2013</td>\n",
       "        <td>173179759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2014</td>\n",
       "        <td>165114361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2015</td>\n",
       "        <td>146112989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016</td>\n",
       "        <td>131165043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2017</td>\n",
       "        <td>113496933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018</td>\n",
       "        <td>102803387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2019</td>\n",
       "        <td>44458570</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2010, 169001153),\n",
       " (2011, 176897208),\n",
       " (2012, 178544324),\n",
       " (2013, 173179759),\n",
       " (2014, 165114361),\n",
       " (2015, 146112989),\n",
       " (2016, 131165043),\n",
       " (2017, 113496933),\n",
       " (2018, 102803387),\n",
       " (2019, 44458570)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "SELECT\n",
    "    YEAR(tpepPickupDateTime) AS current_year,\n",
    "    COUNT(*) AS rides_per_year\n",
    "FROM\n",
    "    OPENROWSET(\n",
    "        BULK 'gold/nyctlc-yellow/puYear=*/puMonth=*/*.parquet',\n",
    "        FORMAT='PARQUET',\n",
    "        DATA_SOURCE='davewdemolake'\n",
    "    ) AS [nyc]\n",
    "WHERE nyc.filepath(1) >= '2010' AND nyc.filepath(1) <= '2019'\n",
    "GROUP BY YEAR(tpepPickupDateTime)\n",
    "ORDER BY 1 ASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now switch to chart view to visualize the data\n",
    "the default should be Chart type=Line, Category=None\n",
    "\n",
    "note that yellow cab rides are precipitously dropping\n",
    "this should make sense given the popularity of Uber and Lyft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CETAS Pattern for Exploratory Data Analytics\n",
    "\n",
    "These queries run pretty fast, considering they are against a remote data lake.  Sometimes \n",
    "the queries are _slow_ and it may make sense to _materialize_ data and queries that we know\n",
    "we are going to do frequent analytics against.  \n",
    "\n",
    "Let's assume the \"decade data query\" above is something we are going to do a lot of analytics against.\n",
    "Let's materialize that data in our local datalake/sandbox using the CETAS pattern.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "--drop external table with data isn't supported\n",
    "CREATE EXTERNAL TABLE taxi_2010_decade\n",
    "WITH (\n",
    "    --adjust your pathing accordingly\n",
    "    --this will write to YOUR sandbox datalake in Synapse\n",
    "    DATA_SOURCE = sandbox,\n",
    "    LOCATION = 'taxi_2010s_decade/',\n",
    "    FILE_FORMAT = ParquetFF\n",
    ") \n",
    "AS\n",
    "--original query\n",
    "SELECT\n",
    "    * \n",
    "FROM\n",
    "    OPENROWSET(\n",
    "        BULK 'gold/nyctlc-yellow/puYear=*/puMonth=*/*.parquet',\n",
    "        FORMAT='PARQUET',\n",
    "        DATA_SOURCE='davewdemolake'\n",
    "    ) AS [nyc]\n",
    "WHERE nyc.filepath(1) >= '2010' AND nyc.filepath(1) <= '2019';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there seasonality to the data? \n",
    "\n",
    "let's just look at a single year (2016) and aggregate by DAY\n",
    "again, graph the data\n",
    "    change it to a column chart, category=current_day\n",
    "\n",
    "we can use our materialized data in our sandbox INSTEAD OF the remote data lake, \n",
    "which might make queries a little faster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>current_day</th>\n",
       "        <th>rides_per_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-01</td>\n",
       "        <td>345037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-02</td>\n",
       "        <td>312831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-03</td>\n",
       "        <td>302878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-04</td>\n",
       "        <td>316171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-05</td>\n",
       "        <td>343251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-06</td>\n",
       "        <td>348516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-07</td>\n",
       "        <td>364894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-08</td>\n",
       "        <td>392070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-09</td>\n",
       "        <td>405825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-10</td>\n",
       "        <td>351788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-11</td>\n",
       "        <td>342651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-12</td>\n",
       "        <td>367390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-13</td>\n",
       "        <td>395090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-14</td>\n",
       "        <td>396473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-15</td>\n",
       "        <td>401289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-16</td>\n",
       "        <td>411899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-17</td>\n",
       "        <td>379156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-18</td>\n",
       "        <td>341481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-19</td>\n",
       "        <td>385187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-20</td>\n",
       "        <td>382105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-21</td>\n",
       "        <td>399654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-22</td>\n",
       "        <td>420162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-23</td>\n",
       "        <td>78133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-24</td>\n",
       "        <td>159766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-25</td>\n",
       "        <td>282087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-26</td>\n",
       "        <td>327655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-27</td>\n",
       "        <td>359180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-28</td>\n",
       "        <td>383326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-29</td>\n",
       "        <td>414039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-30</td>\n",
       "        <td>435369</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2016, 1, 1), 345037),\n",
       " (datetime.date(2016, 1, 2), 312831),\n",
       " (datetime.date(2016, 1, 3), 302878),\n",
       " (datetime.date(2016, 1, 4), 316171),\n",
       " (datetime.date(2016, 1, 5), 343251),\n",
       " (datetime.date(2016, 1, 6), 348516),\n",
       " (datetime.date(2016, 1, 7), 364894),\n",
       " (datetime.date(2016, 1, 8), 392070),\n",
       " (datetime.date(2016, 1, 9), 405825),\n",
       " (datetime.date(2016, 1, 10), 351788),\n",
       " (datetime.date(2016, 1, 11), 342651),\n",
       " (datetime.date(2016, 1, 12), 367390),\n",
       " (datetime.date(2016, 1, 13), 395090),\n",
       " (datetime.date(2016, 1, 14), 396473),\n",
       " (datetime.date(2016, 1, 15), 401289),\n",
       " (datetime.date(2016, 1, 16), 411899),\n",
       " (datetime.date(2016, 1, 17), 379156),\n",
       " (datetime.date(2016, 1, 18), 341481),\n",
       " (datetime.date(2016, 1, 19), 385187),\n",
       " (datetime.date(2016, 1, 20), 382105),\n",
       " (datetime.date(2016, 1, 21), 399654),\n",
       " (datetime.date(2016, 1, 22), 420162),\n",
       " (datetime.date(2016, 1, 23), 78133),\n",
       " (datetime.date(2016, 1, 24), 159766),\n",
       " (datetime.date(2016, 1, 25), 282087),\n",
       " (datetime.date(2016, 1, 26), 327655),\n",
       " (datetime.date(2016, 1, 27), 359180),\n",
       " (datetime.date(2016, 1, 28), 383326),\n",
       " (datetime.date(2016, 1, 29), 414039),\n",
       " (datetime.date(2016, 1, 30), 435369)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT TOP 30\n",
    "    CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n",
    "    COUNT(*) as rides_per_day\n",
    "--now I can simplify the syntax by using the EXTERNAL table on the\n",
    "--FROM clause vs the OPENROWSET\n",
    "FROM taxi_2010_decade\n",
    "WHERE CAST([tpepPickupDateTime] AS DATE) BETWEEN '2016-01-01' AND '2017-01-01'\n",
    "GROUP BY CAST([tpepPickupDateTime] AS DATE)\n",
    "ORDER BY 1 ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "/*\n",
    "    We decide that last query for 2016 taxi rides is something we will use often, so,\n",
    "    let's materialize that too\n",
    "*/\n",
    "--drop external table taxi_2016_by_day\n",
    "CREATE EXTERNAL TABLE taxi_2016_by_day\n",
    "WITH (\n",
    "    --adjust your pathing accordingly\n",
    "    --this will write to YOUR sandbox datalake in Synapse\n",
    "    DATA_SOURCE = sandbox,\n",
    "    LOCATION = 'taxi_2016_by_day/',\n",
    "    FILE_FORMAT = ParquetFF\n",
    ") \n",
    "AS\n",
    "--same query, no changes\n",
    "SELECT\n",
    "    CAST([tpepPickupDateTime] AS DATE) AS [current_day],\n",
    "    COUNT(*) as rides_per_day\n",
    "FROM taxi_2010_decade\n",
    "WHERE CAST([tpepPickupDateTime] AS DATE) BETWEEN '2016-01-01' AND '2017-01-01'\n",
    "GROUP BY CAST([tpepPickupDateTime] AS DATE)\n",
    "ORDER BY 1 ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT TOP 30 * \n",
    "from taxi_2016_by_day\n",
    "ORDER BY 1 ASC;\n",
    ";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "  * there are fewer rides in the summer\n",
    "  * at a weekly level it looks like Saturday is the peak day (we should probably confirm that though)\n",
    "  * there are some significant drops that don't fit a seasonality pattern.  Could this be holidays?  Let's check\n",
    "\n",
    "  Holidays are available as a public dataset that you can connect to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE VIEW holidays\n",
    "AS \n",
    "SELECT\n",
    "    holidayName,\n",
    "    date\n",
    "FROM\n",
    "    OPENROWSET(\n",
    "        BULK 'https://azureopendatastorage.blob.core.windows.net/holidaydatacontainer/Processed/*.parquet',\n",
    "        FORMAT='PARQUET'\n",
    "    ) AS [holidays]\n",
    "WHERE countryOrRegion = 'United States' AND YEAR(date) = 2016\n",
    "\n",
    "--map the holidays to our dataset\n",
    "SELECT  t.current_day, \n",
    "    t.rides_per_day, \n",
    "    h.holidayName,\n",
    "    CASE WHEN h.holidayName IS NOT NULL THEN 1 ELSE 0 END AS IsHoliday\n",
    "FROM taxi_2016_by_day t\n",
    "LEFT JOIN holidays h \n",
    "    ON t.current_day = h.date\n",
    "ORDER BY t.current_day ASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if we chart this it kinda seems like the drop offs do roughy align to holidays.  \n",
    "    we would want to confirm this better, but it's good enough for now.  \n",
    "\n",
    "    What we do see is that Jan 23 has a HUGE drop off and it isn't a holiday.  \n",
    "    Could it be weather?  \n",
    "\n",
    "    Well, it turns out we can get weather data for free from another public dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>avg_windspeed</th>\n",
       "        <th>min_windspeed</th>\n",
       "        <th>max_windspeed</th>\n",
       "        <th>avg_temperature</th>\n",
       "        <th>min_temperature</th>\n",
       "        <th>max_temperature</th>\n",
       "        <th>avg_precipdepth</th>\n",
       "        <th>min_precipdepth</th>\n",
       "        <th>max_precipdepth</th>\n",
       "        <th>avg_snowdepth</th>\n",
       "        <th>min_snowdepth</th>\n",
       "        <th>max_snowdepth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10.059574468085106</td>\n",
       "        <td>3.6</td>\n",
       "        <td>14.9</td>\n",
       "        <td>-1.8191489361702127</td>\n",
       "        <td>-3.0</td>\n",
       "        <td>-0.6</td>\n",
       "        <td>17.454545454545453</td>\n",
       "        <td>0.0</td>\n",
       "        <td>70.0</td>\n",
       "        <td>29.40909090909091</td>\n",
       "        <td>0.0</td>\n",
       "        <td>69.0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(10.059574468085106, 3.6, 14.9, -1.8191489361702127, -3.0, -0.6, 17.454545454545453, 0.0, 70.0, 29.40909090909091, 0.0, 69.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "    AVG(windSpeed) AS avg_windspeed,\n",
    "    MIN(windSpeed) AS min_windspeed,\n",
    "    MAX(windSpeed) AS max_windspeed,\n",
    "    AVG(temperature) AS avg_temperature,\n",
    "    MIN(temperature) AS min_temperature,\n",
    "    MAX(temperature) AS max_temperature,\n",
    "    AVG(precipDepth) AS avg_precipdepth,\n",
    "    MIN(precipDepth) AS min_precipdepth,\n",
    "    MAX(precipDepth) AS max_precipdepth,\n",
    "    AVG(snowDepth) AS avg_snowdepth,\n",
    "    MIN(snowDepth) AS min_snowdepth,\n",
    "    MAX(snowDepth) AS max_snowdepth\n",
    "    --select top 10 * \n",
    "FROM\n",
    "    OPENROWSET(\n",
    "        BULK 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/year=*/month=*/*.parquet',\n",
    "        FORMAT='PARQUET'\n",
    "    ) AS [weather]\n",
    "WHERE countryOrRegion = 'US' \n",
    "AND year = 2016\n",
    "AND CAST([datetime] AS DATE) = '2016-01-23' \n",
    "--let's find the nearest weatherstation to NYC\n",
    "AND stationName = 'JOHN F KENNEDY INTERNATIONAL AIRPORT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Taxi rides probaby dropped on 1/23/2016 due to:\n",
    "\n",
    "* heavy snow (29 cm)\n",
    "* cold (-1C)\n",
    "\n",
    "**Weather and public holidays do correlate with a dropoff in taxi rides.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
