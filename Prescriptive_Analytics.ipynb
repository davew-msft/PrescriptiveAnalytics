{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <center><h1 style=\"color:red;\"><strong><font color = red>Prescriptive Analytics:<br>Taking Analytics to the Next Level</font></strong></h1></center><br>\n",
    "</div>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dave Wentzel  \n",
    "[https://github.com/davew-msft/PrescriptiveAnalytics](https://github.com/davew-msft/PrescriptiveAnalytics)  \n",
    "[My LinkedIn Profile](linkedin.com/in/dwentzel)  \n",
    "Decision Architect  \n",
    "Microsoft Technology Center   \n",
    "Philadelphia PA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide Set-Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## This allows me to put powerpoint slides directly in this notebook.  Could also use RISE, but this is easier.  \n",
    "##\n",
    "from IPython.display import Image\n",
    "def slide(what):\n",
    "    display( Image( \"./slides/\" + what , width = 400, height = 400, retina = True ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Jupyter Navigation\n",
    "\n",
    "* <kbd>CTL</kbd>+<kbd>Enter</kbd> vs <kbd>SHIFT</kbd>+<kbd>Enter</kbd>\n",
    "* Run All Cells \n",
    "* <kbd>ESC</kbd> then a , b , or dd\n",
    "\n",
    "## Tutorials and Useful Links\n",
    "\n",
    "* <a href=\"http://docs.python.org/2/tutorial/\" target=\"_parent\">Python Tutorial</a>\n",
    "* <a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html\" target=\"_parent\">Pandas Tutorial</a>\n",
    "* <a href=\"https://seaborn.pydata.org/tutorial.html\" target=\"_parent\">Seaborn Tutorial</a>\n",
    "* <a href=\"https://www.statsmodels.org/stable/index.html\" target=\"_parent\">Statsmodels Tutorial</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shouldn't be needed\n",
    "# !pip3 install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## ===> Data Manipulation <===\n",
    "##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "##\n",
    "## ===> Data Visualization <===\n",
    "##\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "##\n",
    "## ===> Python Date/Time <===\n",
    "##\n",
    "from datetime import date, time, datetime\n",
    "from dateutil import parser\n",
    "##\n",
    "## ===> Random Number Generators <===\n",
    "##\n",
    "import random\n",
    "##\n",
    "## Log-Normal Distribution\n",
    "##\n",
    "from scipy.stats import lognorm\n",
    "##\n",
    "## ===> Linear Programming <===\n",
    "##\n",
    "from scipy.optimize import linprog\n",
    "##\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## reusable code\n",
    "##\n",
    "bold = '\\033[1m'\n",
    "normal = '\\033[0m'\n",
    "def printbold( s ):\n",
    "    \"\"\"\n",
    "    Print text in bold and the return to normal.\n",
    "    \n",
    "    Args:\n",
    "        s = string.\n",
    "    \"\"\"\n",
    "    print( bold + s + normal )\n",
    "##\n",
    "\n",
    "##\n",
    "## ===> Turn-off Python Warnings <===\n",
    "##\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prescriptive Analytics Methods\n",
    "\n",
    "**_How can we, as data professionals, help to inform decision makers about what actions (decisions) they should take?_**\n",
    "\n",
    "![](./slides/Prescriptive.png)\n",
    "\n",
    "## Positive vs Normative Statements\n",
    "\n",
    "**Positive statements** are based on empirical evidence, can be tested, and involve **NO VALUE JUDGMENTS**. Positive statements contain no indication of approval or disapproval.  We don't value judge, we merely state the facts.  \n",
    "\n",
    "**Normative statements** are when values and opinions start to come into the analysis.  Normative statements express a judgment about what _ought to be_.  \n",
    "\n",
    "[Link to wikipedia article](https://en.wikipedia.org/wiki/Positive_statement).  \n",
    "\n",
    "_Who cares?_\n",
    "\n",
    "Generally, data analysts stick with _positive_ statements.  We shy away from ever making normative statements.  We live in the realm of _positive statements_.  Our statements are based on data, statistics, math, machine learning, linear programming, and _possibly_ econometrics.  \n",
    "\n",
    "But, business people and executives want more out of the data.  _Tell me what to do next?_.  What are the most reasonable courses of actions and their _implications and ramifications_ (I&R) for the **ENTIRE** BUSINESS.  These are normative statements about what _should be _ done.  \n",
    "\n",
    "* A business is a _complex system_.  \n",
    "  * A _complex system_ is a system composed of many interacting parts, such that the collective behavior of those parts together is more than the sum of the individual behaviors.  \n",
    "* A few examples:\n",
    "  * Customer Lifetime Value calculations\n",
    "  * \"If we increase sales by 5%...\"\n",
    "  * demand pricing/price optimization\n",
    "* In a complex system, if we make a decision about one part it will have impacts (I&R) for other parts...possibly undesirable.  \n",
    "  * What appear to be _Narrow Impacts_ tend to actually have _Broad Impacts_, and executives want to know what they _should_ do.  \n",
    "\n",
    "**It is not OUR JOB as analysts to give normative answers to executives, it is our job to help them understand the data and business problem to a degress where we can _help_ the executive understand the normative statements that our data is trying to show them.**\n",
    "\n",
    "\n",
    "One last example:  \n",
    "\n",
    "We sell solutions to B2B customers.  We have teams of sales people, account managers, tech support...all for the purpose of managing our clients.  What should be the composition of the team?  \n",
    "\n",
    "Predictive analytics _could_ tell us the probability of the sale.  \n",
    "\n",
    "What normally happens is that the sales teams will focus on those customers with the highest probability of converting.  \n",
    "\n",
    "Prescriptive analytics might tell us what the teams should look like to make the sale and handle the entire customer lifecycle.  \n",
    "\n",
    "_The Nope List_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The _Hows_ of Prescriptive Analytics\n",
    "\n",
    "First, there is no universally-accepted definition of Prescriptive Analytics.  You may hear it called:\n",
    "* Exploratory Data Analytics (EDA)\n",
    "* Data Profiling\n",
    "* Data Sandboxing\n",
    "\n",
    "We use whatever technique and tool that we are comfortable using to solve the problem.  \n",
    "![](./slides/ppp.png)\n",
    "\n",
    "Possible tools:\n",
    "* ML/AI/Neural Networks\n",
    "* SQL(-based analytics)\n",
    "* Math (Excel/regression)\n",
    "* python/R/SAS/MATLAB/SPSS\n",
    "* Simulations (monte carlo or otherwise)\n",
    "  * great when you have _uncertain_ inputs\n",
    "* Modeling\n",
    "* Linear Programming\n",
    "* Rules-based systems (expert systems, state machines, etc)\n",
    "* INTUITION\n",
    "\n",
    "The tools/methods are often _complementary_ but don't think you MUST use each of these tools or have experts in each.  A little knowledge about each is enough.  Some examples:\n",
    "\n",
    "* if I don't have folks that understand monte carlo sims\n",
    "* if I don't have folks that understand Linear Programming\n",
    "\n",
    "Regardless of tool, we always need data.  But is more data always better?  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "I wish I had time to cover this in detail.  Key points:\n",
    "\n",
    "* Simulations are time-consuming and difficult to create.  \n",
    "* Even with enough time you risk not being able to model all possibilities (or even interesting possibilities)\n",
    "* Discrete-event simulation (DES) ...\n",
    "  * events happen at specific times and we can model them\n",
    "* ...vs continuous simulations\n",
    "  * events occur continuously and with different throughput between time units\n",
    "  * events occur individually at random moments, but collectively occur at an average rate per unit time.  \n",
    "\n",
    "Sometimes we can actually take existing event data and use that as the basis for a simulation.  \n",
    "\n",
    "\n",
    "\n",
    "_Some examples:..._\n",
    "* dwell analytics\n",
    "  * what is the average time a customer spends in _the system_?\n",
    "  * avg time a customer spends waiting in line \n",
    "  * time-average number of customers on the system\n",
    "  * time-average number of customer waiting in line\n",
    "  * how long does fulfillment take?  \n",
    "  * _doordash_\n",
    "* Queueing Theory\n",
    "  * customers waiting in line\n",
    "  * stages in order fulfillment\n",
    "  * manufacturing lines\n",
    "  * Black Friday online sales\n",
    "\n",
    "_Who cares?_\n",
    "\n",
    "Let's say we do some research (maybe an A/B Test) on price elasticity and we determine that a 5% decrease in price should stimulate orders.  But fulfillment becomes an issue as customers have to wait for their order (the queue), resulting in dissatisfied customers that ULTIMATELY causes a HUGE uptick in customer churn.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Marketing Problem that is Really a Queueing Problem (Dwell Analytics)\n",
    "\n",
    "\n",
    "\n",
    "Let's say consumers come into your brick-and-mortar electronics store called _Best By Price_ looking for a product that they've done some initial research on using online retailers.  You've done your research and you determine _price_ is a key factor influencing their purchase with _immediate gratification_ being the next most important factor (ie, if the price differential isn't _too much_ they are willing to pay more NOW to get instant fulfillment vs waiting for 2 day shipping).  \n",
    "\n",
    "We know using econometrics that if the price is lower we should get a lot of shoppers to the store.  Using Queueing Theory and past historical shopping data we should be able to \"model\" things like the `mean time between arrivals` and the `mean arrival rate`.  The `arrival rate` becomes a function of price.  \n",
    "\n",
    "If we set the price too high it will shift the supply/demand curve to the right, causing the probabilities of events to change.  Namely, the inter-arrival times should rise.  This is a simple reduction in demand.  The higher price should spread out the time between customer arrivals.  _What are some cases where this would be helpful?_\n",
    "\n",
    "_You could say we are using econometrics to determine price optimization in this use case.  Price Optimization is one of the most challenging topics in data analytics today.  The above is not the only way to model this, but it's certainly a standard approach._\n",
    "\n",
    "Understanding this \"complex system\" has tons of other benefits to a retailer...the above isn't even, frankly, the most interesting benefit.  \n",
    "\n",
    "Let's look at how we MIGHT model this in code, without introducing historical data, quantity-on-hand, shelf-outs and stock-outs, will the customer get fed up waiting in-line and go elsewhere, etc.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Set queue hyperparameters\n",
    "## https://medium.com/analytics-vidhya/simulating-a-single-server-queuing-system-in-python-f8e32578749f\n",
    "## \n",
    "average_arrival_interval = 5                ## 5 minutes per arrival.  A new shopper arrives every 5 mins\n",
    "arrival_lambd = 1/average_arrival_interval  ## number of arrivals per minute \n",
    "##\n",
    "average_service_time = 3                    ## 3 minutes per service.  ie, a salesperson takes, on avg, 3 minutes servicing a customer\n",
    "service_lambd = 1/average_service_time      ## number served per minute\n",
    "##\n",
    "## Number of events (ie, number of customers serviced)\n",
    "##\n",
    "n_events = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\dave\\git\\PrescriptiveAnalytics\\scripts\\queue.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Import queueing functions\n",
    "## Functions are:\n",
    "##   1. ts_update: a timing utility\n",
    "##   2. queue_run: the main function \n",
    "##   3. queue_summary: a summary function\n",
    "##\n",
    "%run ./scripts/queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Run one queue function for seed = 42 \n",
    "##\n",
    "queue = queue_run( arrival_lambd, service_lambd, n_events, seed = 42 )\n",
    "##\n",
    "## Summarize results\n",
    "##\n",
    "printbold( 'Queue Data\\n' )\n",
    "display( queue.head() )\n",
    "x = queue_summary( queue )\n",
    "printbold( '\\n\\nQueue Summary\\n' )\n",
    "display( x.head() )\n",
    "printbold( f'\\n\\nQueue Statistics\\n' )\n",
    "cols = [ 'time in queue', 'time in server', 'time in system' ]\n",
    "x[ cols ].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multiple queueing experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this data trying to tell us?  \n",
    "\n",
    "`Queue Data` shows us the event history times which may be helpful to see the customer journey and is great for later simulations.  \n",
    "\n",
    "![](./slides/q1.png)\n",
    "\n",
    "`Queue Summary` and `Queue Statistics` shows us important stats\n",
    "\n",
    "![](./slides/q2.png)\n",
    "\n",
    "\n",
    "What I really want to do is run this \"simulation\" a large number of times to see if I can learn anything and offer a \"Next Best Action\" solution to my business users.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Define a run experiment function\n",
    "##\n",
    "def run_experiments( n_runs = 50 ):\n",
    "    df = pd.DataFrame( columns = [ 'time in queue', 'time in server', 'time in system' ] )\n",
    "    cols = list( df )\n",
    "    for i in range( n_runs ):\n",
    "        queue = queue_run( arrival_lambd, service_lambd, n_events, seed = i )\n",
    "        x = queue_summary( queue )\n",
    "        means = x[ cols ].describe().loc['mean']\n",
    "        df = df.append( means )\n",
    "    df.reset_index( inplace = True, drop = True )\n",
    "    df[ 'run number' ] = range( 1, n_runs + 1 )\n",
    "    df = df[ [ 'run number', 'time in queue', 'time in server', 'time in system' ] ] #rearrange columns\n",
    "    return df\n",
    "##\n",
    "## Run the simulation experiment for 100 runs/simulations\n",
    "##\n",
    "n_runs = 10\n",
    "experiments = run_experiments( n_runs = n_runs )\n",
    "display( experiments.head( ) )\n",
    "ax1 = experiments.plot( x = 'run number', y = 'time in queue' )\n",
    "ax1.set_title( 'Time in Queue' )\n",
    "##\n",
    "ax2 = experiments.plot( x = 'run number', y = 'time in system' )\n",
    "ax1.set_title( 'Time in System' )\n",
    "##\n",
    "ax3 = experiments.plot( x = 'run number', y = 'time in server' )\n",
    "ax3.set_title( 'Time in Server' )\n",
    "##\n",
    "ax4 = experiments.plot( x = 'time in server', y = 'time in queue' )\n",
    "ax4.set_title( 'Time in Queue\\nvs.\\Time in Queue' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have I learned with this simulation?\n",
    "\n",
    "Time in Queue:  no matter the use case, this will tell me how long an _actor_ is waiting.  \n",
    "\n",
    "* Approx on average we are waiting maybe 3-4 mins with a lot of variance.  \n",
    "\n",
    "\n",
    "![](./slides/q3.png)\n",
    "\n",
    "* Users are \"in the system\" maybe 7 mins on average, lots of variation\n",
    "\n",
    "![](./slides/q4.png)\n",
    "\n",
    "This shows the q time to \"server\" time.  The pattern shows an exponential distribution with a lot of outliers.  This should be expected.  \n",
    "![](./slides/q5.png)\n",
    "\n",
    "**This method, thinking about problems in terms of Queueing and Simulations, is an interesting way to think about many different business problems and is easily modified to lots of different use cases using this technique.**  I'm a firm believer in modeling all data ingestion activities as _unbounded streams_ into your data lake.  A side benefit of this is that I have a kind of _transaction log_ that I can use to replay these events and base my simulations off of that data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear/Mathematical Programming\n",
    "\n",
    "Mathematical programming is concerned with optimizing an _objective function_ subject to various constraints.  \n",
    "\n",
    "Objective functions:\n",
    "\n",
    "* How do we maximize profits given several products we sell?\n",
    "* How can we manufacture the most products given limited raw materials? \n",
    "* What's the most efficient way to _pack a bin_ or pack a shipping container, given a set of packages?\n",
    "\n",
    "The _optimization_ is always expressed as \n",
    "\n",
    "* minimization:  of cost, wastage, labor\n",
    "* maximization:  profit, revenue, output\n",
    "\n",
    "The _constraints_ are functions where we try to model the real world \"bounds\" using _predicate-style logic_.  The objective functions tend to be _linear_...which just means they can be equality or inequality statements.  Examples:  \n",
    "\n",
    "* `laborhours > 0`\n",
    "* labor laws state I must pay at least $50/hr and we don't want to pay more than $100.  `50 < unitlaborcost < 100`\n",
    "\n",
    "\n",
    "## Who cares?\n",
    "\n",
    "Often a business problem seems complex and our natural tendency (as data scientists) is to say, \"Let's build an ML algorithm to tell us the answer.\"  But often it makes no sense to do that.  The problem may be _deterministic_ and we can definitively and quantifiably determine the correct answer.  \n",
    "\n",
    "_Full disclosure:  not every business problem can be expressed using linear methods.  Some are definitely more _non-linear_.  I'm not smart enough to understand those use cases or the alternative methods to model them.  Sorry._\n",
    "\n",
    "Let's look at an example:  \n",
    "\n",
    "_Your company builds two products Q1 and Q2 which each require different amounts of raw materials X1, X2, and X3.  Knowing that, how can we maximize total output given a set of constraints?_\n",
    "\n",
    "![](./slides/linear.png)\n",
    "\n",
    "_Note that I am hardcoding the parameters in this example, but in the real-world I would constantly run the math to determine how to optimize the system using my current inventory._  \n",
    "\n",
    "Based on the above table I can generate the constraint equations:\n",
    "\n",
    "```\n",
    "Q1 = X1 + X2 + (2 * X3)           # this is the constraint for producing Q1\n",
    "Q2 = (3 * X1) + X2 + X3           # Q2 production constraint\n",
    "Q1 + (3 * Q2) <= 18 X1 units      # available X1 input constraint\n",
    "Q1 + Q2 <= 8                      # X2 input constraint\n",
    "(2*Q1) + Q2 <= 14                 # X3 input constraint\n",
    "Q1 >=0   & Q2 >= 0                # we know we can't produce negative products, but the math doesn't\n",
    "\n",
    "Q = Q1 + (2*Q2)                   # this is the objective function...maximize total output (but we want twice as much Q2)\n",
    "```\n",
    "\n",
    "At this point it is A LOT of effort to explain to you exactly how the math and python works.  But the output is far more interesting:\n",
    "\n",
    "![](./slides/lp1.png)\n",
    "\n",
    "Notes:  \n",
    "* the objective function (red line) is showing what we optimizing for\n",
    "* each dotted line is showing a constraint equation.  They are \"linear\", hence, straight lines (sometimes it's hard to see)\n",
    "* the \"feasible region\" is every combination of outputs that we definitely can produce given the constraints.  This is the black line.  Notice it changes its angle every time a new constraint \"interferes\" with its trajectory.\n",
    "* So, the black line will ALWAYS be the least of all constraints. \n",
    "* the \"optimal solution\" occurs where the feasible region touches the objective function line.  \n",
    "\n",
    "Does this answer make sense?:  \n",
    "* the math tells us we can produce 3 units of Q1 and 5 of Q2 (remember, we want twice the amount of Q2) for 13 total units\n",
    "* given the constraints if you mentally run the numbers that should be the best answer you can come up with\n",
    "\n",
    "_While the math is hard for me to explain, conceptually this is quite simple and easy to explain._  \n",
    "\n",
    "**Now let's look at some code**\n",
    "\n",
    "Again, there is far too much to cover.  Here's some key notes\n",
    "\n",
    "* python states all optimization problems must be minimization.  Ours is a maximization problem, so you'll see we just multiply by -1\n",
    "* you'll see syntax like this:  `[lower,upper]`.  This is the notation for specifying the bounds\n",
    "  * so when we say `X>=0` we are really saying `[0,None]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Scipy setup\n",
    "##\n",
    "## Objective function coefficients: MINIMIZE (it's really a maximize problem, see above)\n",
    "## c means coeffeicent, the 1 and 2 are \"we want twice as much Q2 as Q1\", see above as to why they are negative\n",
    "c = [ -1, -2 ]\n",
    "##\n",
    "## Inequality coefficients\n",
    "## Note the order matches the equation order above\n",
    "##\n",
    "Aub = [ \n",
    "        [ 1, 3 ], \n",
    "        [ 1, 1 ], \n",
    "        [ 2, 1 ]\n",
    "      ]\n",
    "##\n",
    "## Inequality bounds (lhs)\n",
    "##\n",
    "bub = [ 18, 8, 14 ]\n",
    "##\n",
    "## Non-negativity constraints\n",
    "##\n",
    "x1_bounds = ( 0, None )\n",
    "x2_bounds = ( 0, None )\n",
    "##\n",
    "## Do calculation; use revised simplex method\n",
    "##\n",
    "sol = linprog( c, A_ub = Aub, b_ub = bub, bounds = [ x1_bounds, x2_bounds ], method = 'revised simplex' )\n",
    "##\n",
    "## Print solution\n",
    "##\n",
    "print( f'Solution Summary:\\n{sol}' )\n",
    "print( '\\n' )\n",
    "print( f'Coordinates:\\n\\t{sol.x}' )\n",
    "print( f'Optimal value:\\n\\t{round( -1 * sol.fun )}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WidgetCo Example\n",
    "\n",
    "Are you bored yet?  \n",
    "\n",
    "Here's a different business problem:\n",
    "\n",
    "Our company, WidgetCo produces two products:\n",
    "* X1 sells for $20\n",
    "* X2 sells for $15\n",
    "\n",
    "Three inputs are used:\n",
    "* a (60 units in stock)\n",
    "* b (24 units in stock)\n",
    "* c (84 units in stock)\n",
    "\n",
    "Production equations:\n",
    "* X1 = 5a + 3b + 12c\n",
    "* X2 = 15a + 4b + 7c\n",
    "\n",
    ">What is the profit maximizing amount of revenue and how much X1 and X2 will be produced?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Specify objective function prices\n",
    "## Note: use negatives to make a minimization problem to satisfy python issues\n",
    "##\n",
    "obj = [-20, -15]\n",
    "##\n",
    "## Specify LHS constraints (left hand side of equation)\n",
    "##\n",
    "lhs_ineq = [[ 5,  15],\n",
    "            [ 3,  4 ],\n",
    "            [ 12, 7 ] ]\n",
    "##\n",
    "## Specify RHS constraints (right hand side of equation)\n",
    "##\n",
    "rhs_ineq = [ 60, 24, 84 ]\n",
    "##\n",
    "## Specify bounds (inf means infinity, we could also use None)\n",
    "##\n",
    "bnd = [( 0, float( \"inf\" ) ),   # Bounds of x\n",
    "       ( 0, float( \"inf\" ) ) ]  # Bounds of y\n",
    "##\n",
    "## Specify function\n",
    "##\n",
    "opt = linprog(c=obj, A_ub=lhs_ineq, b_ub=rhs_ineq, bounds=bnd, method=\"revised simplex\")\n",
    "##\n",
    "## Calculate revenue.  What we do here is say take the optimum found and calculate the revenue\n",
    "##\n",
    "Rev = 20 * opt.x[ 0 ] + 15 * opt.x[ 1 ]\n",
    "##\n",
    "## Display optimized results\n",
    "##\n",
    "printbold( 'Results:\\n' )\n",
    "print( f'First Product: {round( opt.x[ 0 ], 2)};\\nSecond Product: {round(opt.x[ 1 ], 2)}' )\n",
    "print( f'Profit Maimizing Revenue: ${round( Rev )}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not bored...here's one more business problem example...\n",
    "\n",
    "You are a retailer and you have a budget for $100,000 to stock your shelves.  You can stock your shelves with 2 products:\n",
    "\n",
    "* each X1 costs $1000 and yields a $400 profit\n",
    "* each X2 costs $1500 and yields a $700 profit\n",
    "\n",
    "After some Design Thinking and market research you believe you can sell:\n",
    "* at least 15 X1 but no more than 80.  \n",
    "* at MOST half as many X2\n",
    "\n",
    "> How many of each should be sold to maximize total profit given the budget?  \n",
    "\n",
    "\n",
    "**Notice how the problem is becoming progressively more difficult in business terms but only marginally more difficult in code/math.**  This means we can start to model very complex system behaviors if we simply spend the time to understand the system constraints.  Some other constraints to think about:\n",
    "\n",
    "* tax rates\n",
    "* `risk free rate of return`\n",
    "* supply chain disruptions\n",
    "* market conditions\n",
    "* weather\n",
    "* time of day\n",
    "* other `uncertain variables` (see next section)\n",
    "* randomness (see next section)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## coefficients and constraints\n",
    "c = [ -400, -700 ]\n",
    "A = [ [ -0.5,  1 ], [ 1000,  1500 ] ]\n",
    "b = [ 0, 100000 ]\n",
    "x1_bounds = (15, 80)\n",
    "x2_bounds = (0, None)\n",
    "##\n",
    "## Run LP problem\n",
    "##\n",
    "opt = linprog(c, A_ub = A, b_ub = b, bounds = [ x1_bounds, x2_bounds ], method = 'revised simplex' )\n",
    "Q = 400 * round( opt.x[ 0 ] ) + 700 * round( opt.x[ 1 ] )\n",
    "##\n",
    "## Display optimized results\n",
    "##\n",
    "printbold( 'Results:\\n' )\n",
    "print( f'Number of X1: {round( opt.x[ 0 ] )};\\nNumber of X2 {round( opt.x[ 1 ] )}' )\n",
    "print( f'Optimal Q: {Q}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realistically, what we would do next in the real world is do simulations with the input variables to see what might happen given uncertainty.\n",
    "\n",
    "Here's an example that **every business has problems solving**\n",
    "\n",
    "**PRICE OPTIMIZATION/DEMAND PRICING**\n",
    "\n",
    "Price points for many manufacturing inputs fluctuate daily based on market conditions (the price of copper, the price of jet fuel, etc).  The amount of raw material may also fluctuate based on supply chain shocks.  Your production may vary wildly due to breakdowns, unplanned work, maintenance, and labor issues.  Customer demand may also vary as well due to market conditions.  \n",
    "\n",
    "Each of these \"inputs\" tend to have very skewed distributions.  They tend to cluster around certain areas of the histogram or are constantly and slowly increasing (think:  inflation or the market prices for a product supplied by you and all of your competitors).  If we have _historical data_ to show us these distributions we can build interesting models that tend to be very close to reality.  \n",
    "\n",
    "If we know the data distribution (skew) we can draw from that information to run realistic (and not-quite-so-random) simulations.  The simulations are, in fact, random...but the randomness is drawn from a distribution of data that we've seen historically.  \n",
    "\n",
    "_But this won't handle black swan events very well.  This is where Design Thinking is invaluable_.  \n",
    "\n",
    "Here's a code example which shows how to pull a random number from a distribution of observed historical data, based on data skew we've already seen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Log-Normal Distribution\n",
    "##\n",
    "def lnorm( s, num = 1000 ):\n",
    "    min = lognorm.ppf( 0.01, s )  ## 1th percentile\n",
    "    max = lognorm.ppf( 0.99, s )  ## 99th percentile\n",
    "    x = np.linspace( min, max, num )\n",
    "    plt.plot(x, lognorm.pdf( x, s ), lw = 1, label = 'lognorm pdf' )\n",
    "##\n",
    "lnorm( 1 )\n",
    "lnorm( 0.5 )\n",
    "lnorm( 0.25 )\n",
    "plt.xlim( [ 0, 3 ] )\n",
    "plt.ylim( [ 0, 2 ] )\n",
    "##\n",
    "plt.title( 'Log-Normal Density Function' )\n",
    "plt.ylabel( 'Density' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this is trying to illustrate is how we can inject a little or a lot of variance into our input functions.  \n",
    "\n",
    "Now, let's go back to the WidgetCo example and modify it...so you don't have to scroll up here's the problem again:\n",
    "\n",
    "Our company, WidgetCo produces two products:\n",
    "* X1 sells for $20\n",
    "* X2 sells for $15\n",
    "\n",
    "Three inputs are used:\n",
    "* a (60 units in stock)\n",
    "* b (24 units in stock)\n",
    "* c (84 units in stock)\n",
    "\n",
    "Production equations:\n",
    "* X1 = 5a + 3b + 12c\n",
    "* X2 = 15a + 4b + 7c\n",
    "\n",
    "> What is the profit maximizing amount of revenue and how much X1 and X2 will be produced?  \n",
    "\n",
    "But here's the new requirement:\n",
    "\n",
    "> The inputs above this are merely the MEAN that is available on hand, each with a stdev of 5 , 2, and 8 units respectively.  We can use the log-normal distribution to help us.  We still want to optimize for profit.\n",
    "\n",
    "Let's look at the code to generate a simulation given the new requirements:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Define a function\n",
    "##\n",
    "## this generates the \"random variable\"\n",
    "def lrv( mu, sigma ):\n",
    "    rv = math.log( np.random.lognormal( mean = mu, sigma = sigma, size = None ) )\n",
    "    return( rv )\n",
    "## this is the same set of constraints, give the random variable we generated\n",
    "def lp_run( ):\n",
    "    obj = [-20, -15]\n",
    "    lhs_ineq = [ [ 5,  15 ], [ 3,  4 ], [ 12, 7 ] ]\n",
    "    rhs_ineq = [ round( lrv( mu, sigma ), 0 ) for mu, sigma in [ [ 60, 5 ], [ 24, 2 ], [ 84, 8 ] ] ]\n",
    "    bnd = [( 0, float( \"inf\" ) ), ( 0, float( \"inf\" ) ) ]\n",
    "    opt = linprog(c=obj, A_ub=lhs_ineq, b_ub=rhs_ineq, bounds=bnd, method=\"revised simplex\")\n",
    "    Rev = 20 * opt.x[ 0 ] + 15 * opt.x[ 1 ]\n",
    "    return( Rev, opt )    \n",
    "##\n",
    "## Define a run experiment function\n",
    "## See Queueing example set-up for similar function\n",
    "##\n",
    "def run_experiments( n_runs ):\n",
    "    df = pd.DataFrame( columns = [ 'First Product', 'Second Product', 'Revenue' ] )\n",
    "    cols = list( df )\n",
    "    for i in range( n_runs ):\n",
    "        Rev, opt = lp_run( )\n",
    "        data = { 'First Product':opt.x[ 0 ], 'Second Product':opt.x[ 1 ], 'Revenue':Rev }\n",
    "        x = pd.DataFrame( data, index = [ 0 ] )\n",
    "        frames = [ df, x ]\n",
    "        df = pd.concat( frames )\n",
    "    df[ 'run number' ] = range( 1, n_runs + 1 )\n",
    "    return df\n",
    "##\n",
    "## Run the simulation experiment\n",
    "##\n",
    "n_runs = 100\n",
    "experiments = run_experiments( n_runs )\n",
    "experiments.set_index( 'run number', inplace = True )\n",
    "display( experiments.head( ) )\n",
    "##\n",
    "## Display mean results\n",
    "##\n",
    "printbold( 'Results:\\n' )\n",
    "print( f\"Iterations: {n_runs}\" )\n",
    "print( f\"Mean First Product: {round( experiments[ 'First Product' ].mean(), 0 )}\" )\n",
    "print( f\"Mean Second Product: {round( experiments[ 'Second Product' ].mean(), 0 )}\" )\n",
    "print( f\"Mean Profit Maximizing Revenue: {round( experiments[ 'Revenue' ].mean(), 0 )}\" )\n",
    "##\n",
    "ax = experiments.plot( y = 'Revenue', kind = 'box', grid = False,\n",
    "                 title = 'Profit Maximizing Revenue\\nDistribution' )\n",
    "ax.set( ylabel = 'Revenue ($)' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Thanks for coming out\n",
    "* We are here to help\n",
    "* Could you complete our survey?  \n",
    "\n",
    "Hopefully, some things you learned:  \n",
    "\n",
    "* Why data projects are risky and some approaches for risk mitigation using Prescriptive Analytics\n",
    "* Prescriptive Analytics using \n",
    "  * a Data Lake and SQL\n",
    "  * Jupyter\n",
    "  * simulation\n",
    "  * linear programming\n",
    "\n",
    "_Even if none of this made sense or you think it's too complicated to implement at your company_...\n",
    "\n",
    "* it's good to be exposed to the _Art of the Possible_\n",
    "* by using data as a talking point (with Jupyter notebooks as an enabler) we can often use Design Thinking as a method to come to actionable, normative statements.\n",
    "* _pro tip_:  I wrote none of this code.  You can find all of this in various gh repos and stackoverflow.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
